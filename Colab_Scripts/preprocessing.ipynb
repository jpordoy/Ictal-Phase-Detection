{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read the CSV file into a DataFrame\n",
    "df = pd.read_csv(\"newhr.csv\")\n",
    "\n",
    "# Function to replace -1 values with 10% below the next non-negative value\n",
    "def replace_minus_one(df):\n",
    "    for index, row in df.iterrows():\n",
    "        if row['hr'] == -1:\n",
    "            # Find the next non-negative value\n",
    "            next_index = index + 1\n",
    "            while next_index < len(df) and df.at[next_index, 'hr'] == -1:\n",
    "                next_index += 1\n",
    "            if next_index < len(df):\n",
    "                next_value = df.at[next_index, 'hr']\n",
    "                # Calculate 10% below the next non-negative value\n",
    "                replacement_value = next_value * 0.9\n",
    "                # Replace all -1 values in the sequence with the calculated value\n",
    "                sequence_indices = range(index, next_index)\n",
    "                df.loc[sequence_indices, 'hr'] = replacement_value\n",
    "            else:\n",
    "                # If there are no more non-negative values, interpolate the first value\n",
    "                prev_index = index - 1\n",
    "                while prev_index >= 0 and df.at[prev_index, 'hr'] == -1:\n",
    "                    prev_index -= 1\n",
    "                if prev_index >= 0:\n",
    "                    prev_value = df.at[prev_index, 'hr']\n",
    "                    # Interpolate the first value based on the previous non-negative value\n",
    "                    df.at[index, 'hr'] = prev_value * 1.1  # 10% above the previous non-negative value\n",
    "    return df\n",
    "\n",
    "# Replace -1 values with 10% below the next non-negative value\n",
    "df = replace_minus_one(df)\n",
    "\n",
    "# Save the DataFrame to a new CSV file\n",
    "#df.to_csv('updated_dataset.csv', index=False)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read the CSV file into a DataFrame\n",
    "df = pd.read_csv(\"updated_base_dataset_with_distance.csv\")\n",
    "\n",
    "# Function to compare HR values from row r and row r+1 and adjust if necessary\n",
    "def compare_and_adjust_hr(row, next_row):\n",
    "    hr_r = row['hr']\n",
    "    hr_r_plus_1 = next_row['hr']\n",
    "\n",
    "    # Check if HR values are equal\n",
    "    if hr_r == hr_r_plus_1:\n",
    "        hr_r_plus_1 *= 1.05  # Increase HR value in next row by 5%\n",
    "\n",
    "    return pd.Series([hr_r, hr_r_plus_1])\n",
    "\n",
    "# Add a new column with HR values from row r and row r+1\n",
    "def adjust_hr(df):\n",
    "    hr_values = df.apply(lambda row: compare_and_adjust_hr(row, df.shift(-1).loc[row.name]), axis=1)\n",
    "    df[['hr_r', 'hr_r_plus_1']] = hr_values\n",
    "    return df\n",
    "\n",
    "# Apply the adjustment function\n",
    "df = adjust_hr(df)\n",
    "\n",
    "# Save the DataFrame to a new CSV file\n",
    "df.to_csv('adjusted_hr.csv', index=False)\n",
    "\n",
    "df.head(30)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.interpolate import CubicSpline\n",
    "\n",
    "df = pd.read_csv(\"adjusted_hr.csv\")\n",
    "\n",
    "\n",
    "# Define a function to interpolate values using cubic spline\n",
    "def interpolate_cubic_spline(x, y):\n",
    "    spline = CubicSpline([0, 1], [x, y])\n",
    "    interpolated_values = spline(np.linspace(0, 1, 125))\n",
    "    return interpolated_values\n",
    "\n",
    "# Clean the data\n",
    "df = df.replace([np.inf, -np.inf], np.nan).dropna(subset=['hr_r', 'hr_r_plus_1'])\n",
    "\n",
    "# Assuming your data is stored in a pandas DataFrame called 'df'\n",
    "# Replace 'new_column_name' with the desired name for the new column\n",
    "#df['hrTest'] = df.apply(lambda row: interpolate_cubic_spline(row['hr_r'], row['hr_r_plus_1']), axis=1)\n",
    "\n",
    "df['test'] = df.apply(lambda row: str(list(interpolate_cubic_spline(row['hr_r'], row['hr_r_plus_1']))), axis=1)\n",
    "\n",
    "df.to_csv('test12345.csv', index=False)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.interpolate import CubicSpline\n",
    "\n",
    "# Read the CSV file into a DataFrame\n",
    "df = pd.read_csv(\"adjusted_hr.csv\")\n",
    "\n",
    "# Function to interpolate values for each row\n",
    "def interpolate_values(row):\n",
    "    try:\n",
    "        # Convert the string representation to a list of floats\n",
    "        hr_values = [float(value) for value in row['hr_combined'][1:-1].split(',')]\n",
    "\n",
    "        # Check if all values are finite\n",
    "        if not all(np.isfinite(hr_values)):\n",
    "            return np.nan\n",
    "        \n",
    "        # Adjust values if consecutive values are equal\n",
    "        for i in range(len(hr_values) - 1):\n",
    "            if hr_values[i] == hr_values[i+1]:\n",
    "                hr_values[i+1] *= 1.05  # Increase the second value by 5%\n",
    "        \n",
    "        # Interpolate 125 values between the first and last values using cubic spline\n",
    "        cs = CubicSpline([0, 1], [hr_values[0], hr_values[-1]])\n",
    "        interpolated_values = cs(np.linspace(0, 1, 125))\n",
    "        \n",
    "        # Convert interpolated values to string with commas and enclose in square brackets\n",
    "        interpolated_values_str = '[' + ','.join(map(str, interpolated_values)) + ']'\n",
    "        \n",
    "        return interpolated_values_str\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing row {row.name}: {e}\")\n",
    "        return np.nan\n",
    "\n",
    "# Apply the function to each row and store the result in a new column\n",
    "df['interpolated_values'] = df.apply(interpolate_values, axis=1)\n",
    "\n",
    "# Add a new column to double-check the modified values\n",
    "df['hr_combined_modified'] = df['hr_combined']\n",
    "\n",
    "df.head(30)\n",
    "# Save the DataFrame to a new CSV file\n",
    "df.to_csv('sds1.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.interpolate import CubicSpline\n",
    "\n",
    "# Read the CSV file into a DataFrame\n",
    "df = pd.read_csv(\"updated_base_dataset_with_distance.csv\")\n",
    "\n",
    "# Function to interpolate values for each row\n",
    "def interpolate_values(row):\n",
    "    try:\n",
    "        hr_values = [float(value) for value in row['hr_combined'][1:-1].split(',')]\n",
    "        \n",
    "        # Check if the row needs interpolation\n",
    "        if len(set(hr_values)) == 1:\n",
    "            # If all values in the row are the same, repeat that value\n",
    "            interpolated_values_str = '[' + ','.join([str(hr_values[0])] * 125) + ']'\n",
    "        else:\n",
    "            # Interpolate only if there are more than two unique values\n",
    "            if len(set(hr_values)) > 2:\n",
    "                cs = CubicSpline([0, 1], [hr_values[0], hr_values[-1]])\n",
    "                interpolated_values = cs(np.linspace(0, 1, 125))\n",
    "            else:\n",
    "                interpolated_values = hr_values\n",
    "            interpolated_values_str = '[' + ','.join(map(str, interpolated_values)) + ']'\n",
    "        \n",
    "        return interpolated_values_str\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing row {row.name}: {e}\")\n",
    "        return np.nan\n",
    "\n",
    "# Apply the function to each row and store the result in a new column\n",
    "df['interpolated_values'] = df.apply(interpolate_values, axis=1)\n",
    "\n",
    "# Save the DataFrame to a new CSV file\n",
    "df.to_csv('updated_base_dataset_with_distance_Test.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "df = pd.read_csv(\"orderd_base_dataset.csv\")\n",
    "\n",
    "# Function to calculate overall distance traveled for each row\n",
    "def calculate_overall_distance(row):\n",
    "    if not pd.isnull(row['rawData']):\n",
    "        acceleration_values = np.array(row['rawData'].strip('[]').split(',')).astype(float)\n",
    "        time_interval = 1  # Assuming time interval is 1 second\n",
    "\n",
    "        # Convert acceleration values from milli-g to m/s^2\n",
    "        acceleration_mps2 = acceleration_values * 9.81 / 1000  # 1 g = 9.81 m/s^2\n",
    "        \n",
    "        # Integrate acceleration values twice to obtain distance traveled\n",
    "        velocity = np.cumsum(acceleration_mps2 * time_interval)\n",
    "        displacement = np.cumsum(velocity * time_interval)\n",
    "        \n",
    "        # Calculate total distance traveled\n",
    "        total_distance = displacement[-1]\n",
    "    else:\n",
    "        total_distance = np.nan\n",
    "    \n",
    "    return total_distance\n",
    "\n",
    "# Apply the function to calculate overall distance for each row\n",
    "df['overall_distance'] = df.apply(calculate_overall_distance, axis=1)\n",
    "\n",
    "# Output the DataFrame with the new 'overall_distance' column\n",
    "print(df)\n",
    "# Output the DataFrame with the new 'overall_distance' column to a CSV file\n",
    "df.to_csv('updated_base_dataset_with_distance_taversed.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read the CSV file into DataFrame\n",
    "df = pd.read_csv(\"NEW_BASE_DATASET.csv\")\n",
    "\n",
    "# Calculate overall distance traveled for each row\n",
    "df['overall_distance'] = df.loc[:, 'r1':'r125'].sum(axis=1)\n",
    "\n",
    "# Reorder columns\n",
    "cols = list(df.columns)\n",
    "cols.insert(cols.index('r1'), cols.pop(cols.index('overall_distance')))\n",
    "df = df[cols]\n",
    "\n",
    "# Sort the DataFrame based on the 'Id' column\n",
    "df.sort_values(by='Id', inplace=True)\n",
    "\n",
    "# Save the updated DataFrame to a new CSV file\n",
    "df.to_csv(\"NEW_BASE_DATASET_WITH_DISTANCE.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Set the seed for reproducibility\n",
    "np.random.seed(0)\n",
    "\n",
    "# Generate 125 random decimal values between 72.15459677 and 72.55459677\n",
    "random_values = np.random.uniform( 73.25459677, 73.35459677, 125)\n",
    "\n",
    "# Print the generated random values\n",
    "print(random_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Central value\n",
    "central_value = 72.09\n",
    "\n",
    "# Number of rows and columns\n",
    "num_rows = 9\n",
    "num_columns = 125\n",
    "\n",
    "# Generate the initial array with the central value\n",
    "initial_array = np.full((num_rows, num_columns), central_value, dtype=float)\n",
    "\n",
    "# Generate the sequence of perturbations for each row\n",
    "perturbations = np.linspace(-0.205, 0.205, num_columns)\n",
    "\n",
    "# Apply perturbations to each row\n",
    "for i in range(num_rows):\n",
    "    initial_array[i] += np.random.permutation(perturbations)\n",
    "\n",
    "# Convert array to a list of strings for each row\n",
    "rows_as_strings = ['\\t'.join(map(str, row)) for row in initial_array]\n",
    "\n",
    "# Join rows with newline characters\n",
    "data_for_excel = '\\n'.join(rows_as_strings)\n",
    "\n",
    "# Print the resulting data\n",
    "print(data_for_excel)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read the data from the CSV file into a DataFrame\n",
    "df = pd.read_csv(\"NEW_BASE_DATASET.csv\")\n",
    "\n",
    "# List of columns to drop\n",
    "columns_to_drop = ['hr1','hr_combined']\n",
    "\n",
    "# Create a new DataFrame by dropping the specified columns\n",
    "new_df = df.drop(columns=columns_to_drop)\n",
    "\n",
    "# Print the new DataFrame\n",
    "new_df.to_csv('updated_dataset.csv', index=False)\n",
    "new_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read the data from the CSV file into a DataFrame\n",
    "df = pd.read_csv(\"updated_dataset.csv\")\n",
    "\n",
    "# Get the 'label' column\n",
    "label_column = df.pop('label')\n",
    "\n",
    "# Append the 'label' column to the DataFrame\n",
    "df['label'] = label_column\n",
    "\n",
    "# Print the DataFrame with the 'label' column moved to the far right\n",
    "print(df)\n",
    "df.to_csv('updated_dataset.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the original CSV file\n",
    "df = pd.read_csv('updated_dataset.csv')\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# List of eventIDs to remove\n",
    "eventIDs_to_remove = [764, 1046, 5721, 5745, 5891, 6587, 6590, 6808, 7006, 7434,\n",
    "                      8998, 9005, 12206, 14101, 15208, 15230, 15417, 17219, 21603,\n",
    "                      21855, 21867, 26071, 26987, 27786, 28734, 31397, 31402, 31404,\n",
    "                      36799, 36812, 44115, 45208, 45795, 45800, 47173]\n",
    "\n",
    "\n",
    "\n",
    "# Load the original CSV file\n",
    "df = pd.read_csv('updated_dataset.csv')\n",
    "\n",
    "# Remove rows with eventIDs in the list\n",
    "df = df[~df['eventID'].isin(eventIDs_to_remove)]\n",
    "\n",
    "# Sort the DataFrame by 'eventID' column in ascending order\n",
    "df = df.sort_values(by='eventID', ascending=True)\n",
    "\n",
    "df.to_csv('newdataset11.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import ast\n",
    "\n",
    "# Load the DataFrame\n",
    "df = pd.read_csv(\"formatted_base_dataset.csv\")\n",
    "\n",
    "# Function to calculate overall distance traveled for each row\n",
    "def calculate_overall_distance(row):\n",
    "    if not pd.isnull(row['rawData']):\n",
    "        acceleration_values = np.array(row['rawData'].strip('[]').split(',')).astype(float)\n",
    "        time_interval = 1  # Assuming time interval is 1 second\n",
    "\n",
    "        # Convert acceleration values from milli-g to m/s^2\n",
    "        acceleration_mps2 = acceleration_values * 9.81 / 1000  # 1 g = 9.81 m/s^2\n",
    "        \n",
    "        # Integrate acceleration values twice to obtain distance traveled\n",
    "        velocity = np.cumsum(acceleration_mps2 * time_interval)\n",
    "        displacement = np.cumsum(velocity * time_interval)\n",
    "        \n",
    "        # Calculate total distance traveled\n",
    "        total_distance = displacement[-1]\n",
    "    else:\n",
    "        total_distance = np.nan\n",
    "    \n",
    "    return total_distance\n",
    "\n",
    "# Apply the function to calculate overall distance for each row\n",
    "df['overall_distance'] = df.apply(calculate_overall_distance, axis=1)\n",
    "\n",
    "# Output the DataFrame with the new 'overall_distance' column\n",
    "df.head()\n",
    "df.to_csv('updated_base_dataset_with_distance.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read the CSV file with 'updated_dataset' column into a DataFrame\n",
    "df_updated_dataset = pd.read_csv(\"newdataset.csv\")\n",
    "\n",
    "# Provide column names\n",
    "column_names = ['transposed_labels']\n",
    "\n",
    "# Read the CSV file without column headings\n",
    "df_transposed_labels = pd.read_csv(\"transposed_labels.csv\", header=None, names=column_names)\n",
    "\n",
    "# Check the DataFrame\n",
    "print(df_transposed_labels.head())\n",
    "\n",
    "\n",
    "\n",
    "# Check the columns in the DataFrame\n",
    "print(df_transposed_labels.columns)\n",
    "\n",
    "# Check if 'transposed_labels' column exists in the DataFrame\n",
    "if 'transposed_labels' in df_transposed_labels.columns:\n",
    "    # Create a new DataFrame 'df1' with the desired columns\n",
    "    df1 = pd.DataFrame({\n",
    "        'transposed_labels': df_transposed_labels['transposed_labels'],\n",
    "        'newdataset': df_updated_dataset['eventID']\n",
    "    })\n",
    "\n",
    "    # Print the new DataFrame 'df1'\n",
    "    print(df1)\n",
    "else:\n",
    "    print(\"'transposed_labels' column does not exist in the DataFrame.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.head()\n",
    "df1.to_csv('newlabels1.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the DataFrame\n",
    "df = pd.read_csv(\"NEW_BASE_DATASET_WITH_DISTANCE.csv\")\n",
    "\n",
    "# Repeat each row 125 times\n",
    "df_repeated = df.reindex(df.index.repeat(125))\n",
    "\n",
    "# Reset index to ensure the new DataFrame has a continuous index\n",
    "df_repeated = df_repeated.reset_index(drop=True)\n",
    "\n",
    "# Concatenate the repeated DataFrame with the selected columns from the original DataFrame\n",
    "result_df = pd.concat([df_repeated[['Id', 'eventID', 'hr']]], axis=1)\n",
    "\n",
    "# Print the resulting DataFrame\n",
    "len(result_df)\n",
    "result_df.to_csv('hr_exp.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>eventID</th>\n",
       "      <th>hr</th>\n",
       "      <th>interpolated_hr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>115</td>\n",
       "      <td>80.1</td>\n",
       "      <td>80.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>115</td>\n",
       "      <td>80.1</td>\n",
       "      <td>80.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>115</td>\n",
       "      <td>80.1</td>\n",
       "      <td>89.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>115</td>\n",
       "      <td>80.1</td>\n",
       "      <td>87.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>115</td>\n",
       "      <td>80.1</td>\n",
       "      <td>90.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id  eventID    hr  interpolated_hr\n",
       "0   1      115  80.1             80.1\n",
       "1   1      115  80.1             80.1\n",
       "2   1      115  80.1             89.0\n",
       "3   1      115  80.1             87.0\n",
       "4   1      115  80.1             90.0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.interpolate import CubicSpline\n",
    "\n",
    "# Load the DataFrame\n",
    "df = pd.read_csv(\"hr_exp.csv\")\n",
    "\n",
    "# Introduce a new column to assign unique group identifiers for each consecutive group of 125 values\n",
    "df['group_id'] = np.arange(len(df)) // 125\n",
    "\n",
    "# Define a function to perform cubic spline interpolation\n",
    "def cubic_spline_interpolation(values):\n",
    "    x = np.arange(len(values))\n",
    "    cs = CubicSpline(x, values)\n",
    "    interpolated_values = cs(np.linspace(0, len(values) - 1, 125))\n",
    "    return interpolated_values\n",
    "\n",
    "# Apply cubic spline interpolation within each group\n",
    "interpolated_values_list = []\n",
    "for group_id, group_df in df.groupby('group_id'):\n",
    "    values = group_df['hr']\n",
    "    interpolated_values = cubic_spline_interpolation(values)\n",
    "    interpolated_values_list.extend(interpolated_values)\n",
    "\n",
    "# Create a new column with interpolated values transposed downwards\n",
    "num_rows = len(interpolated_values_list) // 125\n",
    "new_column_values = np.array(interpolated_values_list).reshape(num_rows, 125).transpose().ravel()\n",
    "rounded_values = np.round(new_column_values, 4)  # Round to four decimal places\n",
    "df['interpolated_hr'] = rounded_values[:len(df)]\n",
    "\n",
    "# Drop the temporary 'group_id' column\n",
    "df.drop(columns=['group_id'], inplace=True)\n",
    "\n",
    "# Print the resulting DataFrame\n",
    "df.to_csv('hr_exp1.csv', index=False)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Id  eventID         hr  interpolated_hr\n",
      "0          1      115  80.103221        80.103221\n",
      "1          1      115  80.100294        80.103220\n",
      "2          1      115  80.100048        80.103219\n",
      "3          1      115  80.091512        80.103216\n",
      "4          1      115  80.077638        80.103212\n",
      "...      ...      ...        ...              ...\n",
      "366120  3919    53665  82.006581       114.007734\n",
      "366121  3919    53665  82.000510       114.007887\n",
      "366122  3919    53665  81.998240       114.008039\n",
      "366123  3919    53665  81.988063       114.008190\n",
      "366124  3919    53665  81.979150       114.008341\n",
      "\n",
      "[366125 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.interpolate import CubicSpline\n",
    "\n",
    "# Load the DataFrame\n",
    "df = pd.read_csv(\"hr_exp.csv\")  # Replace \"hr_exp.csv\" with the actual dataset filename\n",
    "\n",
    "# Introduce noise to the original 'hr' values\n",
    "noise_level = 0.01  # Adjust the noise level as needed\n",
    "df['hr'] += np.random.normal(loc=0, scale=noise_level, size=len(df))\n",
    "\n",
    "# Define a function to perform cubic spline interpolation with the next value\n",
    "def cubic_spline_interpolation(values):\n",
    "    interpolated_values = []\n",
    "    for i in range(len(values) - 1):\n",
    "        x = np.array([0, 125])  # Define x-values for interpolation (0 and 125)\n",
    "        y = np.array([values[i], values[i+1]])  # Define y-values for interpolation\n",
    "        cs = CubicSpline(x, y, bc_type='clamped')  # Create CubicSpline object\n",
    "        interpolated_segment = cs(np.linspace(0, 125, 125))  # Interpolate between 0 and 125\n",
    "        interpolated_values.extend(interpolated_segment[:-1])  # Exclude last value to avoid overlap\n",
    "    return interpolated_values\n",
    "\n",
    "# Apply cubic spline interpolation to each group\n",
    "interpolated_values_list = []\n",
    "for group_id, group_df in df.groupby('eventID'):\n",
    "    values = group_df['hr'].to_numpy()\n",
    "    interpolated_values = cubic_spline_interpolation(values)\n",
    "    interpolated_values_list.extend(interpolated_values)\n",
    "\n",
    "# Add the interpolated values to the DataFrame\n",
    "df['interpolated_hr'] = interpolated_values_list[:len(df)]\n",
    "\n",
    "# Print the resulting DataFrame\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('df.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              h1          h2          h3          h4          h5          h6  \\\n",
      "0      80.103221   80.100294   80.100048   80.091512   80.077638   80.096212   \n",
      "1      80.090861   80.099847   80.102149   80.092155   80.099536   80.085395   \n",
      "2      89.003026   88.999340   89.003488   89.012746   88.991172   88.993071   \n",
      "3      87.000118   87.012756   87.009337   86.994985   87.004912   87.021346   \n",
      "4      89.990857   90.004698   89.994394   90.004402   90.019298   89.997031   \n",
      "...          ...         ...         ...         ...         ...         ...   \n",
      "2924  111.997942  111.984436  112.002916  111.999767  112.005866  111.996924   \n",
      "2925  123.213757  123.200535  123.183103  123.193626  123.201247  123.202059   \n",
      "2926  135.506463  135.529051  135.525471  135.493653  135.513697  135.557736   \n",
      "2927   74.021493   74.011848   74.001949   73.998465   74.013226   73.997381   \n",
      "2928   82.000069   82.014780   81.985840   82.006693   82.015424   82.001053   \n",
      "\n",
      "              h7          h8          h9         h10  ...        h116  \\\n",
      "0      80.095826   80.093841   80.110699   80.107754  ...   80.094073   \n",
      "1      80.099369   80.085179   80.101270   80.101226  ...   80.097429   \n",
      "2      88.985423   89.007763   88.994385   89.009419  ...   89.005427   \n",
      "3      87.003433   86.999508   86.996476   86.990989  ...   87.007966   \n",
      "4      90.001714   89.989680   90.008062   89.993567  ...   89.993845   \n",
      "...          ...         ...         ...         ...  ...         ...   \n",
      "2924  111.993338  112.002809  111.986702  112.004475  ...  112.012483   \n",
      "2925  123.187895  123.215830  123.180876  123.195128  ...  123.168186   \n",
      "2926  135.541595  135.514128  135.530805  135.528698  ...  135.519557   \n",
      "2927   73.996319   74.009314   73.999356   73.995699  ...   74.006004   \n",
      "2928   81.990933   82.000016   82.007118   81.996379  ...   82.007976   \n",
      "\n",
      "            h117        h118        h119        h120        h121        h122  \\\n",
      "0      80.107388   80.094828   80.103997   80.110403   80.100826   80.087603   \n",
      "1      80.105267   80.097436   80.108918   80.094735   80.117014   80.113063   \n",
      "2      89.003764   89.015814   88.996704   89.011334   88.991382   88.989932   \n",
      "3      87.011839   86.991202   87.005107   86.993331   87.012076   86.986606   \n",
      "4      90.004577   89.983779   90.011842   90.001945   90.005466   90.006865   \n",
      "...          ...         ...         ...         ...         ...         ...   \n",
      "2924  111.992714  112.003581  112.010521  111.989286  112.000661  112.008990   \n",
      "2925  123.176466  123.188919  123.206201  123.201133  123.191812  123.192038   \n",
      "2926  135.516134  135.525401  135.524195  135.511781  135.522958  135.492479   \n",
      "2927   73.998143   74.016146   74.008141   73.991034   74.003212   74.026734   \n",
      "2928   81.992549   82.002172   82.019432   82.007887   82.006581   82.000510   \n",
      "\n",
      "            h123        h124        h125  \n",
      "0      80.095916   80.118415   80.097973  \n",
      "1      80.089467   80.106057   80.103978  \n",
      "2      89.000221   88.996366   88.985377  \n",
      "3      87.009976   87.007895   87.010399  \n",
      "4      90.011757   89.983549   90.001811  \n",
      "...          ...         ...         ...  \n",
      "2924  112.016112  112.002043  111.992317  \n",
      "2925  123.210776  123.196086  123.219712  \n",
      "2926  135.523376  135.498404  135.519520  \n",
      "2927   73.999824   73.985136   73.994340  \n",
      "2928   81.998240   81.988063   81.979150  \n",
      "\n",
      "[2929 rows x 125 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming df is your DataFrame containing the 'interpolated_hr' column\n",
    "\n",
    "# Initialize an empty DataFrame to store the transposed values\n",
    "transposed_df = pd.read_csv(\"df.csv\")  # Replace \"your_dataset.csv\" with the actual dataset filename\n",
    "\n",
    "df = pd.DataFrame(transposed_df)\n",
    "\n",
    "# Flatten the 'interpolated_hr' column values\n",
    "values = df['hr'].values\n",
    "\n",
    "# Reshape the values into a DataFrame with 125 columns\n",
    "num_rows = len(values) // 125\n",
    "reshaped_values = np.reshape(values[:num_rows * 125], (num_rows, 125))\n",
    "\n",
    "# Create DataFrame with 125 columns\n",
    "transposed_df = pd.DataFrame(reshaped_values, columns=[f'h{i+1}' for i in range(125)])\n",
    "\n",
    "# Print the resulting DataFrame\n",
    "print(transposed_df)\n",
    "transposed_df.to_csv('hr_expe.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
